{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CNN notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from utils.helper import read_data, morphology\n",
    "from tensorflow import keras\n",
    "FOLDER = \"data/data_big_2/\"\n",
    "MORPHOLOGY_ACTIVATED = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Shapes----------------\n",
      "empty: (720, 5, 3, 64, 64)\n",
      "1p: (720, 5, 3, 64, 64)\n",
      "2p: (720, 5, 3, 64, 64)\n",
      "3p: (720, 5, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "data_empty = read_data(FOLDER + \"empty.csv\")\n",
    "data_1p = read_data(FOLDER + \"1p.csv\")\n",
    "data_2p = read_data(FOLDER + \"2p.csv\")\n",
    "data_3p = read_data(FOLDER + \"3p.csv\")\n",
    "print(\"----------------Shapes----------------\")\n",
    "print(\"empty:\", data_empty.shape)\n",
    "print(\"1p:\", data_1p.shape)\n",
    "print(\"2p:\", data_2p.shape)\n",
    "print(\"3p:\", data_3p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH_EMPTY = data_empty.shape[0]\n",
    "LENGTH_1P = data_1p.shape[0]\n",
    "LENGTH_2P = data_2p.shape[0]\n",
    "LENGTH_3P = data_3p.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_empty_summed = np.abs(np.sum(data_empty, axis=1)) \n",
    "data_1p_summed = np.abs(np.sum(data_1p, axis=1))\n",
    "data_2p_summed = np.abs(np.sum(data_2p, axis=1))\n",
    "data_3p_summed = np.abs(np.sum(data_3p, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_empty_summed[:, :, 32, :] = 0\n",
    "data_1p_summed[:, :, 32, :] = 0\n",
    "data_2p_summed[:, :, 32, :] = 0\n",
    "data_3p_summed[:, :, 32, :] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MORPHOLOGY_ACTIVATED == True:\n",
    "    data_empty_summed =  morphology(data_empty_summed)\n",
    "    data_1p_summed =  morphology(data_1p_summed)\n",
    "    data_2p_summed =  morphology(data_2p_summed)\n",
    "    data_3p_summed =  morphology(data_3p_summed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(720, 64, 64, 3)\n",
      "(720, 64, 64, 3)\n",
      "(720, 64, 64, 3)\n",
      "(720, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "data_0 = np.moveaxis(data_empty_summed, 1,3)\n",
    "data_1 = np.moveaxis(data_1p_summed, 1,3)\n",
    "data_2 = np.moveaxis(data_2p_summed, 1,3)\n",
    "data_3 = np.moveaxis(data_3p_summed, 1,3)\n",
    "print(data_0.shape)\n",
    "print(data_1.shape)\n",
    "print(data_2.shape)\n",
    "print(data_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2880, 64, 64, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tot = np.concatenate((data_0, data_1, data_2, data_3), axis=0)\n",
    "data_tot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: (2880,)\n"
     ]
    }
   ],
   "source": [
    "labels_empty = np.zeros(LENGTH_EMPTY)\n",
    "labels_1p = np.ones(LENGTH_1P)\n",
    "labels_2p = np.ones(LENGTH_2P) * 2\n",
    "labels_3p = np.ones(LENGTH_3P) * 3\n",
    "labels = np.concatenate((labels_empty, labels_1p, labels_2p, labels_3p), axis=0)\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels abels one hot shape: (2880, 4)\n"
     ]
    }
   ],
   "source": [
    "train_labels_one_hot = np.eye(4)[labels.astype(int)]\n",
    "print(\"Labels abels one hot shape:\", train_labels_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train_X: (2304, 64, 64, 3)\n",
      "Shape test_X: (576, 64, 64, 3)\n",
      "Shape train_y: (2304, 4)\n",
      "Shape test_y: (576, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(data_tot, train_labels_one_hot, test_size=0.2, stratify = train_labels_one_hot)\n",
    "print(f\"Shape train_X: {train_X.shape}\")\n",
    "print(f\"Shape test_X: {test_X.shape}\")\n",
    "print(f\"Shape train_y: {train_y.shape}\")\n",
    "print(f\"Shape test_y: {test_y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 64, 64, 2)         152       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 32, 32, 2)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 4)         132       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 16, 16, 4)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 8)         296       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 8, 8, 8)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 2052      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,632\n",
      "Trainable params: 2,632\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-26 14:12:28.994990: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "models = keras.models\n",
    "layers = keras.layers\n",
    "\n",
    "# model = models.Sequential(\n",
    "#     [\n",
    "#         layers.Conv2D(8,\n",
    "#                       input_shape = (64,64,3),\n",
    "#                       kernel_size = 5,\n",
    "#                       padding = \"same\",\n",
    "#                       activation = \"relu\"),\n",
    "#         layers.MaxPooling2D(2,\n",
    "#                             strides = None,\n",
    "#                             padding = \"valid\"),\n",
    "#         layers.Conv2D(8,\n",
    "#                       input_shape = (32,32,8),\n",
    "#                       kernel_size = 3,\n",
    "#                       padding = \"same\",\n",
    "#                       activation = \"relu\"),\n",
    "#         layers.MaxPooling2D(2,\n",
    "#                     strides = None,\n",
    "#                     padding = \"valid\"),\n",
    "#         layers.Conv2D(8,\n",
    "#                       input_shape = (16,16,8),\n",
    "#                       kernel_size = 3,\n",
    "#                       padding = \"same\",\n",
    "#                       activation = \"relu\"),\n",
    "#         layers.MaxPooling2D(2,\n",
    "#                     strides = None,\n",
    "#                     padding = \"valid\"),\n",
    "#         layers.Flatten(),\n",
    "#         layers.Dense(4),\n",
    "#         layers.Activation(\"softmax\")\n",
    "#     ]\n",
    "# )\n",
    "model = models.Sequential(\n",
    "    [\n",
    "        layers.Conv2D(2,\n",
    "                      input_shape = (64,64,3),\n",
    "                      kernel_size = 5,\n",
    "                      padding = \"same\",\n",
    "                      activation = \"relu\"),\n",
    "        layers.MaxPooling2D(2,\n",
    "                            strides = None,\n",
    "                            padding = \"valid\"),\n",
    "        layers.Conv2D(4,\n",
    "                      input_shape = (32,32,8),\n",
    "                      kernel_size = 4,\n",
    "                      padding = \"same\",\n",
    "                      activation = \"relu\"),\n",
    "        layers.MaxPooling2D(2,\n",
    "                    strides = None,\n",
    "                    padding = \"valid\"),\n",
    "        layers.Conv2D(8,\n",
    "                      input_shape = (16,16,4),\n",
    "                      kernel_size = 3,\n",
    "                      padding = \"same\",\n",
    "                      activation = \"relu\"),\n",
    "        layers.MaxPooling2D(2,\n",
    "                    strides = None,\n",
    "                    padding = \"valid\"),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(4),\n",
    "        layers.Activation(\"softmax\")\n",
    "    ]\n",
    ")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "65/65 [==============================] - 3s 33ms/step - loss: 1.2192 - accuracy: 0.3623 - val_loss: 1.1245 - val_accuracy: 0.5238\n",
      "Epoch 2/100\n",
      "65/65 [==============================] - 2s 32ms/step - loss: 0.9202 - accuracy: 0.6565 - val_loss: 0.7551 - val_accuracy: 0.7013\n",
      "Epoch 3/100\n",
      "65/65 [==============================] - 2s 30ms/step - loss: 0.6663 - accuracy: 0.7221 - val_loss: 0.6789 - val_accuracy: 0.6797\n",
      "Epoch 4/100\n",
      "65/65 [==============================] - 2s 33ms/step - loss: 0.5428 - accuracy: 0.7665 - val_loss: 0.5253 - val_accuracy: 0.8052\n",
      "Epoch 5/100\n",
      "65/65 [==============================] - 2s 33ms/step - loss: 0.4868 - accuracy: 0.7935 - val_loss: 0.4552 - val_accuracy: 0.8442\n",
      "Epoch 6/100\n",
      "65/65 [==============================] - 2s 32ms/step - loss: 0.4254 - accuracy: 0.8230 - val_loss: 0.4348 - val_accuracy: 0.8615\n",
      "Epoch 7/100\n",
      "65/65 [==============================] - 2s 31ms/step - loss: 0.3816 - accuracy: 0.8471 - val_loss: 0.4147 - val_accuracy: 0.8312\n",
      "Epoch 8/100\n",
      "65/65 [==============================] - 2s 33ms/step - loss: 0.3650 - accuracy: 0.8538 - val_loss: 0.3591 - val_accuracy: 0.8745\n",
      "Epoch 9/100\n",
      "65/65 [==============================] - 2s 32ms/step - loss: 0.3477 - accuracy: 0.8582 - val_loss: 0.4014 - val_accuracy: 0.8312\n",
      "Epoch 10/100\n",
      "65/65 [==============================] - 2s 32ms/step - loss: 0.3152 - accuracy: 0.8717 - val_loss: 0.3584 - val_accuracy: 0.8745\n",
      "Epoch 11/100\n",
      "65/65 [==============================] - 2s 33ms/step - loss: 0.3137 - accuracy: 0.8625 - val_loss: 0.6479 - val_accuracy: 0.7143\n",
      "Epoch 12/100\n",
      "65/65 [==============================] - 2s 32ms/step - loss: 0.3270 - accuracy: 0.8596 - val_loss: 0.3503 - val_accuracy: 0.8788\n",
      "Epoch 13/100\n",
      "65/65 [==============================] - 2s 32ms/step - loss: 0.2813 - accuracy: 0.8857 - val_loss: 0.3725 - val_accuracy: 0.8442\n",
      "Epoch 14/100\n",
      "65/65 [==============================] - 2s 33ms/step - loss: 0.2988 - accuracy: 0.8736 - val_loss: 0.3504 - val_accuracy: 0.8701\n",
      "Epoch 15/100\n",
      "65/65 [==============================] - 2s 32ms/step - loss: 0.2600 - accuracy: 0.8944 - val_loss: 0.3266 - val_accuracy: 0.9048\n",
      "Epoch 16/100\n",
      "65/65 [==============================] - 2s 34ms/step - loss: 0.2660 - accuracy: 0.8944 - val_loss: 0.3222 - val_accuracy: 0.9004\n",
      "Epoch 17/100\n",
      "65/65 [==============================] - 2s 34ms/step - loss: 0.2530 - accuracy: 0.8987 - val_loss: 0.3655 - val_accuracy: 0.8745\n",
      "Epoch 18/100\n",
      "65/65 [==============================] - 2s 32ms/step - loss: 0.2439 - accuracy: 0.8987 - val_loss: 0.3087 - val_accuracy: 0.8961\n",
      "Epoch 19/100\n",
      "65/65 [==============================] - 2s 32ms/step - loss: 0.2326 - accuracy: 0.9064 - val_loss: 0.3546 - val_accuracy: 0.8615\n",
      "Epoch 20/100\n",
      "65/65 [==============================] - 2s 34ms/step - loss: 0.2301 - accuracy: 0.9088 - val_loss: 0.2913 - val_accuracy: 0.8961\n",
      "Epoch 21/100\n",
      "65/65 [==============================] - 2s 32ms/step - loss: 0.2622 - accuracy: 0.8924 - val_loss: 0.2899 - val_accuracy: 0.8874\n",
      "Epoch 22/100\n",
      "65/65 [==============================] - 2s 33ms/step - loss: 0.2131 - accuracy: 0.9170 - val_loss: 0.3178 - val_accuracy: 0.8831\n",
      "Epoch 23/100\n",
      "65/65 [==============================] - 2s 34ms/step - loss: 0.2163 - accuracy: 0.9170 - val_loss: 0.2948 - val_accuracy: 0.8874\n",
      "Epoch 24/100\n",
      "65/65 [==============================] - 2s 33ms/step - loss: 0.2369 - accuracy: 0.9055 - val_loss: 0.2975 - val_accuracy: 0.9048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNN/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/CNN/assets\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_X, train_y,\n",
    "    epochs  = 100,\n",
    "    verbose = 1,\n",
    "    validation_split = 0.1,\n",
    "    shuffle= True,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience = 3),\n",
    "               keras.callbacks.CSVLogger('history/historyCNN.csv')]\n",
    ")\n",
    "if MORPHOLOGY_ACTIVATED == True:\n",
    "    model.save(\"models/CNN_morphology\")\n",
    "else:\n",
    "    model.save(\"models/CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 10ms/step - loss: 0.3235 - accuracy: 0.8594\n",
      "Loss: 0.32350394129753113\n",
      "Accuracy: 0.859375\n"
     ]
    }
   ],
   "source": [
    "loss, aacuracy = model.evaluate(test_X, test_y)\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {aacuracy}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9e121ccb797ab3f030cb728ec4f68e7f9a9ead1118d485a64bc791f040af0d8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
