{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from utils.helper import read_data, morphology\n",
    "from tensorflow import keras\n",
    "FOLDER = \"data/data_big/\"\n",
    "MORPHOLOGY_ACTIVATED = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------Shapes----------------\n",
      "empty: (480, 5, 3, 64, 64)\n",
      "1p: (480, 5, 3, 64, 64)\n",
      "2p: (480, 5, 3, 64, 64)\n",
      "3p: (480, 5, 3, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "data_empty = read_data(FOLDER + \"empty.csv\")\n",
    "data_1p = read_data(FOLDER + \"1p.csv\")\n",
    "data_2p = read_data(FOLDER + \"2p.csv\")\n",
    "data_3p = read_data(FOLDER + \"3p.csv\")\n",
    "print(\"----------------Shapes----------------\")\n",
    "print(\"empty:\", data_empty.shape)\n",
    "print(\"1p:\", data_1p.shape)\n",
    "print(\"2p:\", data_2p.shape)\n",
    "print(\"3p:\", data_3p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LENGTH_EMPTY = data_empty.shape[0]\n",
    "LENGTH_1P = data_1p.shape[0]\n",
    "LENGTH_2P = data_2p.shape[0]\n",
    "LENGTH_3P = data_3p.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_empty_summed = np.abs(data_empty) \n",
    "data_1p_summed = np.abs(data_1p)\n",
    "data_2p_summed = np.abs(data_2p)\n",
    "data_3p_summed = np.abs(data_3p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_empty_summed[:, :, :, 32, :] = 0\n",
    "data_1p_summed[:, :, :, 32, :] = 0\n",
    "data_2p_summed[:, :, :, 32, :] = 0\n",
    "data_3p_summed[:, :, :, 32, :] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(480, 5, 64, 64, 3)\n",
      "(480, 5, 64, 64, 3)\n",
      "(480, 5, 64, 64, 3)\n",
      "(480, 5, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "data_0 = np.moveaxis(data_empty_summed, 2,4)\n",
    "data_1 = np.moveaxis(data_1p_summed, 2,4)\n",
    "data_2 = np.moveaxis(data_2p_summed, 2,4)\n",
    "data_3 = np.moveaxis(data_3p_summed, 2,4)\n",
    "print(data_0.shape)\n",
    "print(data_1.shape)\n",
    "print(data_2.shape)\n",
    "print(data_3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1920, 5, 64, 64, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tot = np.concatenate((data_0, data_1, data_2, data_3), axis=0)\n",
    "data_tot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels shape: (1920,)\n"
     ]
    }
   ],
   "source": [
    "labels_empty = np.zeros(LENGTH_EMPTY)\n",
    "labels_1p = np.ones(LENGTH_1P)\n",
    "labels_2p = np.ones(LENGTH_2P) * 2\n",
    "labels_3p = np.ones(LENGTH_3P) * 3\n",
    "labels = np.concatenate((labels_empty, labels_1p, labels_2p, labels_3p), axis=0)\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels abels one hot shape: (1920, 4)\n"
     ]
    }
   ],
   "source": [
    "train_labels_one_hot = np.eye(4)[labels.astype(int)]\n",
    "print(\"Labels abels one hot shape:\", train_labels_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape train_X: (1536, 5, 64, 64, 3)\n",
      "Shape test_X: (384, 5, 64, 64, 3)\n",
      "Shape train_y: (1536, 4)\n",
      "Shape test_y: (384, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(data_tot, train_labels_one_hot, test_size=0.2, stratify = train_labels_one_hot)\n",
    "print(f\"Shape train_X: {train_X.shape}\")\n",
    "print(f\"Shape test_X: {test_X.shape}\")\n",
    "print(f\"Shape train_y: {train_y.shape}\")\n",
    "print(f\"Shape test_y: {test_y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " time_distributed_32 (TimeDi  (None, 5, 64, 64, 8)     608       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_33 (TimeDi  (None, 5, 32, 32, 8)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_34 (TimeDi  (None, 5, 32, 32, 4)     804       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_35 (TimeDi  (None, 5, 16, 16, 4)     0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_36 (TimeDi  (None, 5, 16, 16, 4)     404       \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_37 (TimeDi  (None, 5, 8, 8, 4)       0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " time_distributed_38 (TimeDi  (None, 5, 256)           0         \n",
      " stributed)                                                      \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 5)                 5240      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4)                 24        \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,080\n",
      "Trainable params: 7,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.Input(shape=(5, 64, 64, 3)))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Conv2D(8,\n",
    "                      input_shape = (64,64,3),\n",
    "                      kernel_size = 5,\n",
    "                      padding = \"same\",\n",
    "                      activation = \"relu\")))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.MaxPooling2D(2,\n",
    "                                strides = None,\n",
    "                                padding = \"valid\")))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Conv2D(4,\n",
    "                      input_shape = (32,32,3),\n",
    "                      kernel_size = 5,\n",
    "                      padding = \"same\",\n",
    "                      activation = \"relu\")))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.MaxPooling2D(2,\n",
    "                                strides = None,\n",
    "                                padding = \"valid\")))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Conv2D(4,\n",
    "                      input_shape = (16,16,3),\n",
    "                      kernel_size = 5,\n",
    "                      padding = \"same\",\n",
    "                      activation = \"relu\")))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.MaxPooling2D(2,\n",
    "                                strides = None,\n",
    "                                padding = \"valid\")))\n",
    "model.add(keras.layers.TimeDistributed(keras.layers.Flatten()))\n",
    "# define LSTM model\n",
    "model.add(keras.layers.LSTM(5))\n",
    "model.add(keras.layers.Dense(4))\n",
    "model.add(keras.layers.Activation(\"softmax\"))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "44/44 [==============================] - 9s 173ms/step - loss: 1.2989 - accuracy: 0.4168 - val_loss: 1.1218 - val_accuracy: 0.6039\n",
      "Epoch 2/100\n",
      "44/44 [==============================] - 9s 194ms/step - loss: 0.9548 - accuracy: 0.6223 - val_loss: 0.7799 - val_accuracy: 0.6558\n",
      "Epoch 3/100\n",
      "44/44 [==============================] - 7s 165ms/step - loss: 0.8073 - accuracy: 0.7041 - val_loss: 0.6807 - val_accuracy: 0.7468\n",
      "Epoch 4/100\n",
      "44/44 [==============================] - 7s 167ms/step - loss: 0.7564 - accuracy: 0.6903 - val_loss: 0.6393 - val_accuracy: 0.7662\n",
      "Epoch 5/100\n",
      "44/44 [==============================] - 7s 167ms/step - loss: 0.6767 - accuracy: 0.7410 - val_loss: 0.5553 - val_accuracy: 0.7987\n",
      "Epoch 6/100\n",
      "44/44 [==============================] - 7s 165ms/step - loss: 0.6383 - accuracy: 0.7554 - val_loss: 0.5113 - val_accuracy: 0.8052\n",
      "Epoch 7/100\n",
      "44/44 [==============================] - 7s 162ms/step - loss: 0.5997 - accuracy: 0.7750 - val_loss: 0.5675 - val_accuracy: 0.7792\n",
      "Epoch 8/100\n",
      "44/44 [==============================] - 7s 162ms/step - loss: 0.6108 - accuracy: 0.7612 - val_loss: 0.4787 - val_accuracy: 0.8182\n",
      "Epoch 9/100\n",
      "44/44 [==============================] - 7s 162ms/step - loss: 0.5355 - accuracy: 0.8111 - val_loss: 0.4694 - val_accuracy: 0.8312\n",
      "Epoch 10/100\n",
      "44/44 [==============================] - 7s 161ms/step - loss: 0.5122 - accuracy: 0.8082 - val_loss: 0.4835 - val_accuracy: 0.8052\n",
      "Epoch 11/100\n",
      "44/44 [==============================] - 7s 163ms/step - loss: 0.5051 - accuracy: 0.8133 - val_loss: 0.4931 - val_accuracy: 0.8052\n",
      "Epoch 12/100\n",
      "44/44 [==============================] - 7s 159ms/step - loss: 0.4930 - accuracy: 0.8213 - val_loss: 0.4144 - val_accuracy: 0.8312\n",
      "Epoch 13/100\n",
      "44/44 [==============================] - 8s 194ms/step - loss: 0.4817 - accuracy: 0.8227 - val_loss: 0.3668 - val_accuracy: 0.8831\n",
      "Epoch 14/100\n",
      "44/44 [==============================] - 9s 201ms/step - loss: 0.4926 - accuracy: 0.7996 - val_loss: 0.4270 - val_accuracy: 0.8117\n",
      "Epoch 15/100\n",
      "44/44 [==============================] - 8s 173ms/step - loss: 0.4468 - accuracy: 0.8357 - val_loss: 0.3589 - val_accuracy: 0.8636\n",
      "Epoch 16/100\n",
      "44/44 [==============================] - 7s 170ms/step - loss: 0.4498 - accuracy: 0.8242 - val_loss: 0.3588 - val_accuracy: 0.8766\n",
      "Epoch 17/100\n",
      "44/44 [==============================] - 8s 175ms/step - loss: 0.4091 - accuracy: 0.8640 - val_loss: 0.3715 - val_accuracy: 0.8636\n",
      "Epoch 18/100\n",
      "44/44 [==============================] - 8s 173ms/step - loss: 0.4164 - accuracy: 0.8430 - val_loss: 0.3228 - val_accuracy: 0.8961\n",
      "Epoch 19/100\n",
      "44/44 [==============================] - 7s 166ms/step - loss: 0.3876 - accuracy: 0.8524 - val_loss: 0.3575 - val_accuracy: 0.8377\n",
      "Epoch 20/100\n",
      "44/44 [==============================] - 7s 164ms/step - loss: 0.3983 - accuracy: 0.8603 - val_loss: 0.3021 - val_accuracy: 0.9026\n",
      "Epoch 21/100\n",
      "44/44 [==============================] - 7s 169ms/step - loss: 0.3676 - accuracy: 0.8632 - val_loss: 0.3072 - val_accuracy: 0.8766\n",
      "Epoch 22/100\n",
      "44/44 [==============================] - 7s 169ms/step - loss: 0.3585 - accuracy: 0.8690 - val_loss: 0.2860 - val_accuracy: 0.8766\n",
      "Epoch 23/100\n",
      "44/44 [==============================] - 8s 171ms/step - loss: 0.3360 - accuracy: 0.8792 - val_loss: 0.3016 - val_accuracy: 0.8766\n",
      "Epoch 24/100\n",
      "44/44 [==============================] - 7s 165ms/step - loss: 0.4058 - accuracy: 0.8401 - val_loss: 0.2863 - val_accuracy: 0.8701\n",
      "Epoch 25/100\n",
      "44/44 [==============================] - 7s 166ms/step - loss: 0.3372 - accuracy: 0.8748 - val_loss: 0.3123 - val_accuracy: 0.8766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/LSTM/assets\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    optimizer = keras.optimizers.Adam(learning_rate = 0.001),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    train_X, train_y,\n",
    "    epochs  = 100,\n",
    "    verbose = 1,\n",
    "    validation_split = 0.1,\n",
    "    shuffle= True,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience = 3),\n",
    "               keras.callbacks.CSVLogger('history/historyLSTM.csv')]\n",
    ")\n",
    "\n",
    "model.save(\"models/LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 1s 65ms/step - loss: 0.3403 - accuracy: 0.8594\n",
      "Loss: 0.340273380279541\n",
      "Accuracy: 0.859375\n"
     ]
    }
   ],
   "source": [
    "loss, aacuracy = model.evaluate(test_X, test_y)\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {aacuracy}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9e121ccb797ab3f030cb728ec4f68e7f9a9ead1118d485a64bc791f040af0d8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
